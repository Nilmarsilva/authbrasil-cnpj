# ðŸš€ OtimizaÃ§Ã£o do PostgreSQL para AuthBrasil CNPJ

## ðŸ“Š VisÃ£o Geral

Com **~135 milhÃµes de registros**, precisamos de otimizaÃ§Ãµes agressivas para manter performance.

---

## ðŸŽ¯ EstratÃ©gias Implementadas

### 1. **Ãndices Otimizados**

#### Ãndices B-Tree (PadrÃ£o)
- `cnpj_basico` (todas as tabelas) - Chave de relacionamento
- `cnpj_completo` (estabelecimentos) - Busca por CNPJ
- `razao_social` (empresas) - OrdenaÃ§Ã£o alfabÃ©tica
- `uf`, `municipio` (estabelecimentos) - Filtros regionais

#### Ãndices GIN (Full-Text Search)
```sql
-- Busca por nome aproximado (trigram)
CREATE INDEX idx_empresas_razao_social_trgm 
ON empresas USING gin(razao_social gin_trgm_ops);

-- Busca por nome fantasia
CREATE INDEX idx_estabelecimentos_nome_fantasia_trgm 
ON estabelecimentos USING gin(nome_fantasia gin_trgm_ops);

-- Busca por nome de sÃ³cio
CREATE INDEX idx_socios_nome_socio_trgm 
ON socios USING gin(nome_socio gin_trgm_ops);
```

**BenefÃ­cio:** Busca tipo "LIKE %termo%" rÃ¡pida (~10-100x mais rÃ¡pido)

#### Ãndices Compostos
```sql
-- Buscar por UF + SituaÃ§Ã£o
CREATE INDEX idx_estabelecimentos_uf_situacao 
ON estabelecimentos(uf, situacao_cadastral);

-- Buscar por MunicÃ­pio + CNAE
CREATE INDEX idx_estabelecimentos_municipio_cnae 
ON estabelecimentos(municipio, cnae_fiscal_principal);
```

**BenefÃ­cio:** Queries com WHERE combinado sÃ£o muito mais rÃ¡pidas

#### Ãndices Parciais
```sql
-- Apenas estabelecimentos ativos (economiza espaÃ§o)
CREATE INDEX idx_estabelecimentos_ativos 
ON estabelecimentos(cnpj_completo) 
WHERE situacao_cadastral = '02';

-- Apenas matrizes
CREATE INDEX idx_estabelecimentos_matrizes 
ON estabelecimentos(cnpj_basico) 
WHERE identificador_matriz_filial = '1';
```

**BenefÃ­cio:** Ãndices menores = queries mais rÃ¡pidas + menos disco

---

### 2. **VACUUM e Autovacuum**

#### O que Ã© VACUUM?
- Remove linhas "mortas" (deleted/updated)
- Libera espaÃ§o em disco
- Atualiza estatÃ­sticas do planner

#### ConfiguraÃ§Ã£o Autovacuum
```sql
-- Para tabelas grandes (>10M linhas)
ALTER TABLE estabelecimentos SET (
    autovacuum_vacuum_scale_factor = 0.05,     -- 5% de linhas mortas
    autovacuum_vacuum_threshold = 10000,       -- MÃ­nimo 10k linhas
    autovacuum_analyze_scale_factor = 0.02,    -- 2% para anÃ¡lise
    autovacuum_analyze_threshold = 5000        -- MÃ­nimo 5k linhas
);
```

#### VACUUM Manual
```bash
# VACUUM normal (nÃ£o bloqueia)
python backend/scripts/optimize_database.py

# VACUUM FULL (reescreve tabela, BLOQUEIA!)
# Apenas durante manutenÃ§Ã£o programada
psql -U postgres -d authbrasil_cnpj -c "VACUUM FULL VERBOSE estabelecimentos"
```

**FrequÃªncia Recomendada:**
- Autovacuum: AutomÃ¡tico (configurado)
- VACUUM ANALYZE: Semanal (via cron)
- VACUUM FULL: Semestral (janela de manutenÃ§Ã£o)

---

### 3. **ConfiguraÃ§Ã£o do PostgreSQL**

#### `postgresql.conf` Otimizado

```ini
# MemÃ³ria
shared_buffers = 2GB              # 25% da RAM (8GB)
effective_cache_size = 6GB        # 75% da RAM
work_mem = 50MB                   # Para sorts/joins
maintenance_work_mem = 512MB      # Para VACUUM/CREATE INDEX

# Checkpoints
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100   # EstatÃ­sticas mais precisas

# Autovacuum
autovacuum = on
autovacuum_max_workers = 3
autovacuum_naptime = 10s          # Verifica a cada 10s

# Planner
random_page_cost = 1.1            # Para SSD (padrÃ£o=4.0)
effective_io_concurrency = 200    # Para SSD
```

#### Como Aplicar
```bash
# 1. Editar arquivo de configuraÃ§Ã£o
sudo nano /etc/postgresql/16/main/postgresql.conf

# 2. Reiniciar PostgreSQL
sudo systemctl restart postgresql

# 3. Verificar
psql -U postgres -c "SHOW shared_buffers"
```

---

### 4. **Particionamento de Tabelas (Futuro)**

Para tabelas com **>50M registros**, considerar particionamento:

```sql
-- Particionar estabelecimentos por UF
CREATE TABLE estabelecimentos_sp PARTITION OF estabelecimentos
FOR VALUES IN ('SP');

CREATE TABLE estabelecimentos_rj PARTITION OF estabelecimentos
FOR VALUES IN ('RJ');

-- etc...
```

**BenefÃ­cios:**
- Queries em SP sÃ³ leem partiÃ§Ã£o SP
- VACUUM mais rÃ¡pido (por partiÃ§Ã£o)
- ManutenÃ§Ã£o independente

**Quando Implementar:**
- Quando queries por UF forem >70% do total
- Ou quando tabela passar de 100M linhas

---

### 5. **Monitoramento**

#### Queries Lentas
```sql
-- Habilitar log de queries lentas
ALTER DATABASE authbrasil_cnpj SET log_min_duration_statement = 1000;  -- >1s

-- Ver queries mais lentas
SELECT 
    query,
    calls,
    total_time / 1000 / 60 as total_minutes,
    mean_time / 1000 as mean_seconds
FROM pg_stat_statements
WHERE query NOT LIKE '%pg_stat%'
ORDER BY total_time DESC
LIMIT 20;
```

#### Tamanho das Tabelas
```sql
SELECT 
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

#### Ãndices NÃ£o Utilizados
```sql
-- Ãndices que nunca sÃ£o usados (candidatos para remoÃ§Ã£o)
SELECT 
    schemaname, tablename, indexname,
    idx_scan as scans,
    pg_size_pretty(pg_relation_size(indexrelid)) as size
FROM pg_stat_user_indexes
WHERE idx_scan = 0
AND indexrelname NOT LIKE '%_pkey'
ORDER BY pg_relation_size(indexrelid) DESC;
```

---

### 6. **Cache (Redis)**

Para queries frequentes, usar Redis:

```python
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379, db=0)

async def get_empresa_cached(cnpj_basico: str):
    # Tentar cache primeiro
    cache_key = f"empresa:{cnpj_basico}"
    cached = redis_client.get(cache_key)
    
    if cached:
        return json.loads(cached)
    
    # Se nÃ£o estiver em cache, buscar no DB
    empresa = await db.query(Empresa).filter(...).first()
    
    # Guardar em cache (24h)
    redis_client.setex(cache_key, 86400, json.dumps(empresa))
    
    return empresa
```

**Queries para Cachear:**
- Busca por CNPJ completo
- Empresas mais consultadas
- Tabelas auxiliares (CNAEs, MunicÃ­pios, etc)

---

## ðŸ”§ Scripts de ManutenÃ§Ã£o

### OtimizaÃ§Ã£o Completa
```bash
python backend/scripts/optimize_database.py
```

**O que faz:**
1. Configura autovacuum
2. Cria Ã­ndices full-text
3. Cria Ã­ndices compostos
4. Cria Ã­ndices parciais
5. Executa VACUUM ANALYZE
6. Mostra estatÃ­sticas

### Cron Job (ManutenÃ§Ã£o AutomÃ¡tica)
```bash
# Editar crontab
crontab -e

# Adicionar linha (todo domingo Ã s 2h)
0 2 * * 0 cd /path/to/backend && python scripts/optimize_database.py >> /var/log/db_optimize.log 2>&1
```

---

## ðŸ“ˆ Benchmarks Esperados

| OperaÃ§Ã£o | Sem OtimizaÃ§Ã£o | Com OtimizaÃ§Ã£o | Melhora |
|----------|----------------|----------------|---------|
| Busca por CNPJ | ~500ms | ~10ms | 50x |
| Busca por nome (LIKE) | ~30s | ~300ms | 100x |
| Busca por UF + CNAE | ~10s | ~100ms | 100x |
| Join Empresa + Estabelecimento | ~2s | ~50ms | 40x |
| Count total (estabelecimentos) | ~15s | ~50ms | 300x |

---

## âš ï¸ Avisos Importantes

### VACUUM FULL
- **BLOQUEIA a tabela** durante execuÃ§Ã£o
- Pode demorar horas em tabelas grandes
- Apenas em janela de manutenÃ§Ã£o programada
- **NÃƒO rodar em produÃ§Ã£o sem aviso!**

### Ãndices
- Cada Ã­ndice **aumenta tempo de INSERT/UPDATE**
- Ãndices nÃ£o usados **desperdiÃ§am espaÃ§o**
- Monitorar uso com `pg_stat_user_indexes`

### MemÃ³ria
- `shared_buffers` > 25% RAM pode piorar performance
- `work_mem` muito alto = risco de OOM (Out of Memory)
- Sempre testar antes de aplicar em produÃ§Ã£o

---

## ðŸ“š ReferÃªncias

- [PostgreSQL Performance Tuning](https://wiki.postgresql.org/wiki/Performance_Optimization)
- [pg_trgm Extension](https://www.postgresql.org/docs/current/pgtrgm.html)
- [VACUUM Best Practices](https://www.postgresql.org/docs/current/sql-vacuum.html)
- [Effective use of PostgreSQL Indexes](https://www.postgresql.org/docs/current/indexes.html)

---

**Ãšltima atualizaÃ§Ã£o:** 22/11/2024  
**VersÃ£o PostgreSQL:** 16+
